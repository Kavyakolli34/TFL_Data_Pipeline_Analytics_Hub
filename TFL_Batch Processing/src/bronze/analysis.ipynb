{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3153f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\Kavya\\OneDrive\\Documents\\TFL\\DATAAnalysis\\data\\tfl_arrivals.csv\",\n",
    "    header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171c78d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  0           1   2    3   \\\n",
      "0  Tfl.Api.Presentation.Entities.Prediction, Tfl.... -1016672935   1  225   \n",
      "1  Tfl.Api.Presentation.Entities.Prediction, Tfl....  1775985613   1  241   \n",
      "2  Tfl.Api.Presentation.Entities.Prediction, Tfl....  1715108579   1  274   \n",
      "3  Tfl.Api.Presentation.Entities.Prediction, Tfl.... -1864629153   1  270   \n",
      "4  Tfl.Api.Presentation.Entities.Prediction, Tfl.... -1864432545   1  240   \n",
      "\n",
      "            4                                  5         6         7   \\\n",
      "0  940GZZLUFPK  Finsbury Park Underground Station  victoria  Victoria   \n",
      "1  940GZZLUVIC       Victoria Underground Station  victoria  Victoria   \n",
      "2  940GZZLUGPK     Green Park Underground Station  victoria  Victoria   \n",
      "3  940GZZLUGPK     Green Park Underground Station  victoria  Victoria   \n",
      "4  940GZZLUGPK     Green Park Underground Station  victoria  Victoria   \n",
      "\n",
      "                        8         9   ...           11  \\\n",
      "0  Southbound - Platform 4   inbound  ...  940GZZLUBXN   \n",
      "1  Southbound - Platform 4   inbound  ...  940GZZLUBXN   \n",
      "2  Northbound - Platform 3  outbound  ...  940GZZLUWWL   \n",
      "3  Southbound - Platform 4   inbound  ...  940GZZLUBXN   \n",
      "4  Southbound - Platform 4   inbound  ...  940GZZLUBXN   \n",
      "\n",
      "                                        12                            13  \\\n",
      "0              Brixton Underground Station  2025-11-26T16:40:05.2255652Z   \n",
      "1              Brixton Underground Station  2025-11-26T16:40:05.2255652Z   \n",
      "2  Walthamstow Central Underground Station  2025-11-26T16:40:05.2255652Z   \n",
      "3              Brixton Underground Station  2025-11-26T16:40:05.2255652Z   \n",
      "4              Brixton Underground Station  2025-11-26T16:40:05.2255652Z   \n",
      "\n",
      "     14                                               15                   16  \\\n",
      "0    81          Between Seven Sisters and Finsbury Park              Brixton   \n",
      "1  1311  Between Walthamstow Central and Blackhorse Road              Brixton   \n",
      "2    80                                      At Victoria  Walthamstow Central   \n",
      "3   830                      At Seven Sisters Platform 5              Brixton   \n",
      "4   890                          Departed Tottenham Hale              Brixton   \n",
      "\n",
      "                     17                    18    19  \\\n",
      "0  2025-11-26T16:41:26Z  2025-11-26T16:41:26Z  tube   \n",
      "1  2025-11-26T17:01:56Z  2025-11-26T17:01:56Z  tube   \n",
      "2  2025-11-26T16:41:25Z  2025-11-26T16:41:25Z  tube   \n",
      "3  2025-11-26T16:53:55Z  2025-11-26T16:53:55Z  tube   \n",
      "4  2025-11-26T16:54:55Z  2025-11-26T16:54:55Z  tube   \n",
      "\n",
      "                                                  20  \n",
      "0  {'$type': 'Tfl.Api.Presentation.Entities.Predi...  \n",
      "1  {'$type': 'Tfl.Api.Presentation.Entities.Predi...  \n",
      "2  {'$type': 'Tfl.Api.Presentation.Entities.Predi...  \n",
      "3  {'$type': 'Tfl.Api.Presentation.Entities.Predi...  \n",
      "4  {'$type': 'Tfl.Api.Presentation.Entities.Predi...  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30783828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2686, 21)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44dee681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate rows:\", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4259454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_values: 0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "5        0\n",
      "6        0\n",
      "7        0\n",
      "8        0\n",
      "9     1108\n",
      "10    1969\n",
      "11       0\n",
      "12       0\n",
      "13       0\n",
      "14       0\n",
      "15       0\n",
      "16       0\n",
      "17       0\n",
      "18       0\n",
      "19       0\n",
      "20     134\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"null_values:\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea6be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"$type\",\n",
    "    \"id\",\n",
    "    \"operationType\",\n",
    "    \"vehicleId\",\n",
    "    \"naptanId\",\n",
    "    \"stationName\",\n",
    "    \"lineId\",\n",
    "    \"lineName\",\n",
    "    \"platformName\",\n",
    "    \"direction\",\n",
    "    \"bearing\",\n",
    "    \"destinationNaptanId\",\n",
    "    \"destinationName\",\n",
    "    \"timestamp\",\n",
    "    \"timeToStation\",\n",
    "    \"currentLocation\",\n",
    "    \"towards\",\n",
    "    \"expectedArrival\",\n",
    "    \"timeToLive\",\n",
    "    \"modeName\",\n",
    "    \"timing\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eafc470",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = column_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e6688ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               $type          id  \\\n",
      "0  Tfl.Api.Presentation.Entities.Prediction, Tfl.... -1016672935   \n",
      "1  Tfl.Api.Presentation.Entities.Prediction, Tfl....  1775985613   \n",
      "2  Tfl.Api.Presentation.Entities.Prediction, Tfl....  1715108579   \n",
      "3  Tfl.Api.Presentation.Entities.Prediction, Tfl.... -1864629153   \n",
      "4  Tfl.Api.Presentation.Entities.Prediction, Tfl.... -1864432545   \n",
      "\n",
      "   operationType  vehicleId     naptanId                        stationName  \\\n",
      "0              1        225  940GZZLUFPK  Finsbury Park Underground Station   \n",
      "1              1        241  940GZZLUVIC       Victoria Underground Station   \n",
      "2              1        274  940GZZLUGPK     Green Park Underground Station   \n",
      "3              1        270  940GZZLUGPK     Green Park Underground Station   \n",
      "4              1        240  940GZZLUGPK     Green Park Underground Station   \n",
      "\n",
      "     lineId  lineName             platformName direction  ...  \\\n",
      "0  victoria  Victoria  Southbound - Platform 4   inbound  ...   \n",
      "1  victoria  Victoria  Southbound - Platform 4   inbound  ...   \n",
      "2  victoria  Victoria  Northbound - Platform 3  outbound  ...   \n",
      "3  victoria  Victoria  Southbound - Platform 4   inbound  ...   \n",
      "4  victoria  Victoria  Southbound - Platform 4   inbound  ...   \n",
      "\n",
      "  destinationNaptanId                          destinationName  \\\n",
      "0         940GZZLUBXN              Brixton Underground Station   \n",
      "1         940GZZLUBXN              Brixton Underground Station   \n",
      "2         940GZZLUWWL  Walthamstow Central Underground Station   \n",
      "3         940GZZLUBXN              Brixton Underground Station   \n",
      "4         940GZZLUBXN              Brixton Underground Station   \n",
      "\n",
      "                      timestamp timeToStation  \\\n",
      "0  2025-11-26T16:40:05.2255652Z            81   \n",
      "1  2025-11-26T16:40:05.2255652Z          1311   \n",
      "2  2025-11-26T16:40:05.2255652Z            80   \n",
      "3  2025-11-26T16:40:05.2255652Z           830   \n",
      "4  2025-11-26T16:40:05.2255652Z           890   \n",
      "\n",
      "                                   currentLocation              towards  \\\n",
      "0          Between Seven Sisters and Finsbury Park              Brixton   \n",
      "1  Between Walthamstow Central and Blackhorse Road              Brixton   \n",
      "2                                      At Victoria  Walthamstow Central   \n",
      "3                      At Seven Sisters Platform 5              Brixton   \n",
      "4                          Departed Tottenham Hale              Brixton   \n",
      "\n",
      "        expectedArrival            timeToLive modeName  \\\n",
      "0  2025-11-26T16:41:26Z  2025-11-26T16:41:26Z     tube   \n",
      "1  2025-11-26T17:01:56Z  2025-11-26T17:01:56Z     tube   \n",
      "2  2025-11-26T16:41:25Z  2025-11-26T16:41:25Z     tube   \n",
      "3  2025-11-26T16:53:55Z  2025-11-26T16:53:55Z     tube   \n",
      "4  2025-11-26T16:54:55Z  2025-11-26T16:54:55Z     tube   \n",
      "\n",
      "                                              timing  \n",
      "0  {'$type': 'Tfl.Api.Presentation.Entities.Predi...  \n",
      "1  {'$type': 'Tfl.Api.Presentation.Entities.Predi...  \n",
      "2  {'$type': 'Tfl.Api.Presentation.Entities.Predi...  \n",
      "3  {'$type': 'Tfl.Api.Presentation.Entities.Predi...  \n",
      "4  {'$type': 'Tfl.Api.Presentation.Entities.Predi...  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Index(['$type', 'id', 'operationType', 'vehicleId', 'naptanId', 'stationName',\n",
      "       'lineId', 'lineName', 'platformName', 'direction', 'bearing',\n",
      "       'destinationNaptanId', 'destinationName', 'timestamp', 'timeToStation',\n",
      "       'currentLocation', 'towards', 'expectedArrival', 'timeToLive',\n",
      "       'modeName', 'timing'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9cfea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null_values: $type                     0\n",
      "id                        0\n",
      "operationType             0\n",
      "vehicleId                 0\n",
      "naptanId                  0\n",
      "stationName               0\n",
      "lineId                    0\n",
      "lineName                  0\n",
      "platformName              0\n",
      "direction              1108\n",
      "bearing                1969\n",
      "destinationNaptanId       0\n",
      "destinationName           0\n",
      "timestamp                 0\n",
      "timeToStation             0\n",
      "currentLocation           0\n",
      "towards                   0\n",
      "expectedArrival           0\n",
      "timeToLive                0\n",
      "modeName                  0\n",
      "timing                  134\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"null_values:\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f78a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "#Check FULL duplicate rows\n",
    "\n",
    "full_duplicates = df[df.duplicated()]\n",
    "\n",
    "print(\"Full duplicate rows:\", full_duplicates.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0dba9",
   "metadata": {},
   "source": [
    "**Check logical duplicates**\n",
    "1. same train with same arrival time / depature time appears mutiple times only timestamp changes- still it counted as no duplicate becuase of time stamp.\n",
    "2. so [\"id\", \"vehicleId\", \"expectedArrival\"] are unique \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9694b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logical duplicate rows: 1228\n"
     ]
    }
   ],
   "source": [
    "#subset--checks only important columns ; keep=False -- shows all copies, not just one\n",
    "\n",
    "keep=False → shows all copies, not just one\n",
    "logical_duplicates = df[df.duplicated(\n",
    "    subset=[\"id\", \"vehicleId\", \"expectedArrival\"],\n",
    "    keep=False\n",
    ")]\n",
    "\n",
    "print(\"Logical duplicate rows:\", logical_duplicates.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9707fd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationName</th>\n",
       "      <th>vehicleId</th>\n",
       "      <th>expectedArrival</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>King's Cross St. Pancras Underground Station</td>\n",
       "      <td>202</td>\n",
       "      <td>2025-11-26T16:45:08Z</td>\n",
       "      <td>2025-11-26T16:44:06.8338759Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>King's Cross St. Pancras Underground Station</td>\n",
       "      <td>202</td>\n",
       "      <td>2025-11-26T16:45:08Z</td>\n",
       "      <td>2025-11-26T16:45:06.1352808Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Euston Underground Station</td>\n",
       "      <td>202</td>\n",
       "      <td>2025-11-26T16:46:32Z</td>\n",
       "      <td>2025-11-26T16:45:06.1352808Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>Euston Underground Station</td>\n",
       "      <td>202</td>\n",
       "      <td>2025-11-26T16:46:32Z</td>\n",
       "      <td>2025-11-26T16:45:08.8907362Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>Euston Underground Station</td>\n",
       "      <td>202</td>\n",
       "      <td>2025-11-26T16:46:32Z</td>\n",
       "      <td>2025-11-26T16:46:11.2987753Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>Victoria Underground Station</td>\n",
       "      <td>277</td>\n",
       "      <td>2025-11-26T17:05:42Z</td>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>Vauxhall Underground Station</td>\n",
       "      <td>277</td>\n",
       "      <td>2025-11-26T17:09:41Z</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>Vauxhall Underground Station</td>\n",
       "      <td>277</td>\n",
       "      <td>2025-11-26T17:09:41Z</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>Stockwell Underground Station</td>\n",
       "      <td>277</td>\n",
       "      <td>2025-11-26T17:10:42Z</td>\n",
       "      <td>1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>Stockwell Underground Station</td>\n",
       "      <td>277</td>\n",
       "      <td>2025-11-26T17:10:42Z</td>\n",
       "      <td>1336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1228 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       stationName  vehicleId  \\\n",
       "620   King's Cross St. Pancras Underground Station        202   \n",
       "886   King's Cross St. Pancras Underground Station        202   \n",
       "795                     Euston Underground Station        202   \n",
       "1128                    Euston Underground Station        202   \n",
       "1454                    Euston Underground Station        202   \n",
       "...                                            ...        ...   \n",
       "2205                  Victoria Underground Station        277   \n",
       "1743                  Vauxhall Underground Station        277   \n",
       "2111                  Vauxhall Underground Station        277   \n",
       "1647                 Stockwell Underground Station        277   \n",
       "2010                 Stockwell Underground Station        277   \n",
       "\n",
       "           expectedArrival                     timestamp  \n",
       "620   2025-11-26T16:45:08Z  2025-11-26T16:44:06.8338759Z  \n",
       "886   2025-11-26T16:45:08Z  2025-11-26T16:45:06.1352808Z  \n",
       "795   2025-11-26T16:46:32Z  2025-11-26T16:45:06.1352808Z  \n",
       "1128  2025-11-26T16:46:32Z  2025-11-26T16:45:08.8907362Z  \n",
       "1454  2025-11-26T16:46:32Z  2025-11-26T16:46:11.2987753Z  \n",
       "...                    ...                           ...  \n",
       "2205  2025-11-26T17:05:42Z                          1036  \n",
       "1743  2025-11-26T17:09:41Z                          1337  \n",
       "2111  2025-11-26T17:09:41Z                          1275  \n",
       "1647  2025-11-26T17:10:42Z                          1398  \n",
       "2010  2025-11-26T17:10:42Z                          1336  \n",
       "\n",
       "[1228 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view those logical duplicates \n",
    "\n",
    "logical_duplicates[\n",
    "    [\"stationName\", \"vehicleId\", \"expectedArrival\", \"timestamp\"]\n",
    "].sort_values([\"vehicleId\", \"expectedArrival\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a2e7a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#Read all 6 CSV files\n",
    "\n",
    "FILES = {\n",
    "    \"Central\": \"data/Central.csv\",\n",
    "    \"Northern\": \"data/Northern.csv\",\n",
    "    \"Victoria\": \"data/Victoria.csv\",\n",
    "    \"Piccadilly\": \"data/Piccadilly.csv\",\n",
    "    \"Metropolitan\": \"data/Metropolitan.csv\",\n",
    "    \"Bakerloo\": \"data/Bakerloo.csv\"\n",
    "}\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "for line, path in FILES.items():\n",
    "    df = pd.read_csv(path)  \n",
    "    df[\"source_file\"] = line\n",
    "    dataframes[line] = df\n",
    "\n",
    "print(\"All files loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3014f5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN COUNT CHECK\n",
      "Central: 28 columns\n",
      "Northern: 28 columns\n",
      "Victoria: 28 columns\n",
      "Piccadilly: 28 columns\n",
      "Metropolitan: 28 columns\n",
      "Bakerloo: 28 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"COLUMN COUNT CHECK\")\n",
    "\n",
    "for line, df in dataframes.items():\n",
    "    print(f\"{line}: {len(df.columns)} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e97027f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROW COUNT CHECK\n",
      "Central: 1473 rows\n",
      "Northern: 1923 rows\n",
      "Victoria: 691 rows\n",
      "Piccadilly: 1370 rows\n",
      "Metropolitan: 499 rows\n",
      "Bakerloo: 524 rows\n"
     ]
    }
   ],
   "source": [
    "#count check \n",
    "\n",
    "print(\"ROW COUNT CHECK\")\n",
    "for line, df in dataframes.items():\n",
    "    print(f\"{line}: {df.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2043f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL COLUMN NAMES PER FILE\n",
      "\n",
      " Central (28 columns):\n",
      "$type\n",
      "id\n",
      "operationType\n",
      "vehicleId\n",
      "naptanId\n",
      "stationName\n",
      "lineId\n",
      "lineName\n",
      "platformName\n",
      "direction\n",
      "bearing\n",
      "destinationNaptanId\n",
      "destinationName\n",
      "timestamp\n",
      "timeToStation\n",
      "currentLocation\n",
      "towards\n",
      "expectedArrival\n",
      "timeToLive\n",
      "modeName\n",
      "timing.$type\n",
      "timing.countdownServerAdjustment\n",
      "timing.source\n",
      "timing.insert\n",
      "timing.read\n",
      "timing.sent\n",
      "timing.received\n",
      "source_file\n",
      "\n",
      " Northern (28 columns):\n",
      "$type\n",
      "id\n",
      "operationType\n",
      "vehicleId\n",
      "naptanId\n",
      "stationName\n",
      "lineId\n",
      "lineName\n",
      "platformName\n",
      "direction\n",
      "bearing\n",
      "destinationNaptanId\n",
      "destinationName\n",
      "timestamp\n",
      "timeToStation\n",
      "currentLocation\n",
      "towards\n",
      "expectedArrival\n",
      "timeToLive\n",
      "modeName\n",
      "timing.$type\n",
      "timing.countdownServerAdjustment\n",
      "timing.source\n",
      "timing.insert\n",
      "timing.read\n",
      "timing.sent\n",
      "timing.received\n",
      "source_file\n",
      "\n",
      " Victoria (28 columns):\n",
      "$type\n",
      "id\n",
      "operationType\n",
      "vehicleId\n",
      "naptanId\n",
      "stationName\n",
      "lineId\n",
      "lineName\n",
      "platformName\n",
      "direction\n",
      "bearing\n",
      "destinationNaptanId\n",
      "destinationName\n",
      "timestamp\n",
      "timeToStation\n",
      "currentLocation\n",
      "towards\n",
      "expectedArrival\n",
      "timeToLive\n",
      "modeName\n",
      "timing.$type\n",
      "timing.countdownServerAdjustment\n",
      "timing.source\n",
      "timing.insert\n",
      "timing.read\n",
      "timing.sent\n",
      "timing.received\n",
      "source_file\n",
      "\n",
      " Piccadilly (28 columns):\n",
      "$type\n",
      "id\n",
      "operationType\n",
      "vehicleId\n",
      "naptanId\n",
      "stationName\n",
      "lineId\n",
      "lineName\n",
      "platformName\n",
      "direction\n",
      "bearing\n",
      "destinationNaptanId\n",
      "destinationName\n",
      "timestamp\n",
      "timeToStation\n",
      "currentLocation\n",
      "towards\n",
      "expectedArrival\n",
      "timeToLive\n",
      "modeName\n",
      "timing.$type\n",
      "timing.countdownServerAdjustment\n",
      "timing.source\n",
      "timing.insert\n",
      "timing.read\n",
      "timing.sent\n",
      "timing.received\n",
      "source_file\n",
      "\n",
      " Metropolitan (28 columns):\n",
      "$type\n",
      "id\n",
      "operationType\n",
      "vehicleId\n",
      "naptanId\n",
      "stationName\n",
      "lineId\n",
      "lineName\n",
      "platformName\n",
      "bearing\n",
      "timestamp\n",
      "timeToStation\n",
      "currentLocation\n",
      "towards\n",
      "expectedArrival\n",
      "timeToLive\n",
      "modeName\n",
      "timing.$type\n",
      "timing.countdownServerAdjustment\n",
      "timing.source\n",
      "timing.insert\n",
      "timing.read\n",
      "timing.sent\n",
      "timing.received\n",
      "direction\n",
      "destinationNaptanId\n",
      "destinationName\n",
      "source_file\n",
      "\n",
      " Bakerloo (28 columns):\n",
      "$type\n",
      "id\n",
      "operationType\n",
      "vehicleId\n",
      "naptanId\n",
      "stationName\n",
      "lineId\n",
      "lineName\n",
      "platformName\n",
      "direction\n",
      "bearing\n",
      "destinationNaptanId\n",
      "destinationName\n",
      "timestamp\n",
      "timeToStation\n",
      "currentLocation\n",
      "towards\n",
      "expectedArrival\n",
      "timeToLive\n",
      "modeName\n",
      "timing.$type\n",
      "timing.countdownServerAdjustment\n",
      "timing.source\n",
      "timing.insert\n",
      "timing.read\n",
      "timing.sent\n",
      "timing.received\n",
      "source_file\n"
     ]
    }
   ],
   "source": [
    "print(\"ALL COLUMN NAMES PER FILE\")\n",
    "\n",
    "for line, df in dataframes.items():\n",
    "    print(f\"\\n {line} ({len(df.columns)} columns):\")\n",
    "    for col in df.columns:\n",
    "        print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e780781d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE COLUMNS ACROSS ALL FILES\n",
      "$type\n",
      "bearing\n",
      "currentLocation\n",
      "destinationName\n",
      "destinationNaptanId\n",
      "direction\n",
      "expectedArrival\n",
      "id\n",
      "lineId\n",
      "lineName\n",
      "modeName\n",
      "naptanId\n",
      "operationType\n",
      "platformName\n",
      "source_file\n",
      "stationName\n",
      "timeToLive\n",
      "timeToStation\n",
      "timestamp\n",
      "timing.$type\n",
      "timing.countdownServerAdjustment\n",
      "timing.insert\n",
      "timing.read\n",
      "timing.received\n",
      "timing.sent\n",
      "timing.source\n",
      "towards\n",
      "vehicleId\n"
     ]
    }
   ],
   "source": [
    "all_columns = set()\n",
    "\n",
    "for df in dataframes.values():\n",
    "    all_columns.update(df.columns)\n",
    "\n",
    "print(\"UNIQUE COLUMNS ACROSS ALL FILES\")\n",
    "for col in sorted(all_columns):\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea06b162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL VALUE ANALYSIS\n",
      "\n",
      " Central\n",
      "Total null values: 1543\n",
      "\n",
      " Northern\n",
      "Total null values: 2025\n",
      "\n",
      " Victoria\n",
      "Total null values: 771\n",
      "\n",
      " Piccadilly\n",
      "Total null values: 1488\n",
      "\n",
      " Metropolitan\n",
      "Total null values: 980\n",
      "\n",
      " Bakerloo\n",
      "Total null values: 623\n"
     ]
    }
   ],
   "source": [
    "# check null values \n",
    "\n",
    "print(\"NULL VALUE ANALYSIS\")\n",
    "\n",
    "for line, df in dataframes.items():\n",
    "    print(f\"\\n {line}\")\n",
    "    print(\"Total null values:\", df.isnull().sum().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef6650b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL VALUES PER COLUMN (PER DATASET)\n",
      "\n",
      "DATASET: Central\n",
      "direction : 70\n",
      "bearing : 1473\n",
      "--------------------------------------------------\n",
      "DATASET: Northern\n",
      "direction : 100\n",
      "bearing : 1923\n",
      "currentLocation : 2\n",
      "--------------------------------------------------\n",
      "DATASET: Victoria\n",
      "direction : 80\n",
      "bearing : 691\n",
      "--------------------------------------------------\n",
      "DATASET: Piccadilly\n",
      "direction : 57\n",
      "bearing : 1370\n",
      "destinationNaptanId : 12\n",
      "destinationName : 12\n",
      "currentLocation : 37\n",
      "--------------------------------------------------\n",
      "DATASET: Metropolitan\n",
      "bearing : 499\n",
      "currentLocation : 19\n",
      "direction : 190\n",
      "destinationNaptanId : 136\n",
      "destinationName : 136\n",
      "--------------------------------------------------\n",
      "DATASET: Bakerloo\n",
      "direction : 81\n",
      "bearing : 524\n",
      "destinationNaptanId : 9\n",
      "destinationName : 9\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#perdataset per coloumn - null value count\n",
    "\n",
    "print(\"NULL VALUES PER COLUMN (PER DATASET)\\n\")\n",
    "\n",
    "for line, df in dataframes.items():\n",
    "    print(f\"DATASET: {line}\")\n",
    "    \n",
    "    null_counts = df.isnull().sum()\n",
    "    \n",
    "    # Print only columns that actually have nulls\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    \n",
    "    if null_counts.empty:\n",
    "        print(\"No null values found\")\n",
    "    else:\n",
    "        for col, count in null_counts.items():\n",
    "            print(f\"{col} : {count}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0466d253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL DUPLICATE CHECK (PER DATASET)\n",
      "Central: 0 full duplicate rows\n",
      "Northern: 0 full duplicate rows\n",
      "Victoria: 0 full duplicate rows\n",
      "Piccadilly: 0 full duplicate rows\n",
      "Metropolitan: 0 full duplicate rows\n",
      "Bakerloo: 0 full duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# check duplicates per dataset\n",
    "\n",
    "print(\"FULL DUPLICATE CHECK (PER DATASET)\")\n",
    "\n",
    "for line, df in dataframes.items():\n",
    "    full_dup_count = df.duplicated().sum()\n",
    "    print(f\"{line}: {full_dup_count} full duplicate rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "717851a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGICAL DUPLICATE CHECK (PER DATASET)\n",
      "Central: 10 logical duplicates\n",
      "Northern: 6 logical duplicates\n",
      "Victoria: 3 logical duplicates\n",
      "Piccadilly: 6 logical duplicates\n",
      "Metropolitan: 4 logical duplicates\n",
      "Bakerloo: 1 logical duplicates\n"
     ]
    }
   ],
   "source": [
    "# check logical duplicates\n",
    "#Logical duplicate = same train, same station, same arrival time\n",
    "\n",
    "print(\"LOGICAL DUPLICATE CHECK (PER DATASET)\")\n",
    "\n",
    "for line, df in dataframes.items():\n",
    "    logical_dup_count = df.duplicated(\n",
    "        subset=[\"vehicleId\", \"stationName\", \"expectedArrival\"]\n",
    "    ).sum()\n",
    "\n",
    "    print(f\"{line}: {logical_dup_count} logical duplicates\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
